{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z-tufekci/DeepLearning/blob/main/ResNet_for_Face_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=25, resize=0.5)\n",
        "X = lfw_people.images\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "#print(target_names)\n",
        "n_classes = target_names.shape[0]\n",
        "print(\"# of class: \",n_classes)\n",
        "print(\"# of samples: \",n_samples)\n",
        "print(\"Image size: \",h,\"x\",w)"
      ],
      "metadata": {
        "id": "U6FaLyHVrGjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,axs = plt.subplots(6,6,figsize=(36,36))\n",
        "for i in range(36):\n",
        "    r=i//6\n",
        "    c=i%6\n",
        "    axs[r][c].set_xticks([])\n",
        "    axs[r][c].set_yticks([])\n",
        "    axs[r][c].imshow(X[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JFCsdlt2Rq7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=41)"
      ],
      "metadata": {
        "id": "81dsS81trRyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as  tf\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)"
      ],
      "metadata": {
        "id": "EcojfUFIrSZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsE6dbZNj9cH"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import os\n",
        "from math import ceil\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaRB4C7-msTY"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 \n",
        "epochs = 200\n",
        "\n",
        "num_classes = n_classes\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n_points = len(X_train)\n",
        "print('n_points:' , n_points, 'batch_size:', batch_size)\n",
        "steps_per_epoch = ceil(n_points / batch_size)\n",
        "print('stepper_epoch:' , steps_per_epoch)\n",
        "\n",
        "if subtract_pixel_mean:\n",
        "    X_train_mean = np.mean(X_train, axis=0)\n",
        "    X_train -= X_train_mean\n",
        "    X_test -= X_train_mean\n",
        "\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(list(X_train.shape) + [1])\n",
        "input_shape = X_train.shape[1:]"
      ],
      "metadata": {
        "id": "NY_bdlsItZjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2xTB5mH14XW"
      },
      "outputs": [],
      "source": [
        "print('y_train shape:', y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbvPSvqg25EK"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):  \n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_bytOGaKbzp"
      },
      "outputs": [],
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "  \n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same', #We want to maintain the shape same during block\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    print(\" activation: \", activation,\" bn: \", batch_normalization,\" kernelsize: \", kernel_size,\" stri \", strides,\"  number of filters\",num_filters)\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_As1kAMU3KPa"
      },
      "outputs": [],
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=34):\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    print(\"INPUT CNN LAYER\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs) # CONV2D\n",
        "    for stack in range(3):    #STACK=3     STACK0: BLOCK0 --> STACK1: BLOCK0 -->stride=2(divide size by 2) kernel1 STACK2: BLOCK0 stride=2(divide size by 2) kernel1\n",
        "       print(\"STACK\",stack+1)\n",
        "       for res_block in range(num_res_blocks): #BLOCK=1\n",
        "            strides = 1\n",
        "\n",
        "            if stack > 0 and res_block == 0:\n",
        "                strides = 2\n",
        "                print(\"DOWNSAMPLING\") \n",
        "            \n",
        "            print(\"   BLOCK\",res_block+1)\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "\n",
        "            if stack > 0 and res_block == 0: \n",
        "                print(\"KERNEL SIZE 1x1\")\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            print(\"CONCATENATE\")\n",
        "            x = keras.layers.add([x, y])\n",
        "            print(\"ACTIVATION RELU\" )\n",
        "            x = Activation('relu')(x)\n",
        "            print(\"END OF BLOCK\" )\n",
        "       print(\"num_filters x 2\")     \n",
        "       num_filters *= 2\n",
        "       print(\"END OF STACK\" )\n",
        "    print(\"AVERAGE POOLING\" ) \n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "   \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETzUyTkkKYU1"
      },
      "outputs": [],
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=34):\n",
        "\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    for stage in range(3):   # resnet_layer, st0: n=3  16->64 cnnxx 64->128  st1: st2: \n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                print(\"KERNEL SIZE 1\")\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    y = Dense(512, activation = 'relu')(y)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dQLDGEfMNks"
      },
      "outputs": [],
      "source": [
        "n = 9 # block number\n",
        "version = 1\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "print(model_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnZggelTMA9t"
      },
      "outputs": [],
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth, num_classes=n_classes)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth, num_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDbTrkZwMEF8"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmawJs3PMmGB"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKhSnOETMtRt"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "callbacks = [lr_reducer, lr_scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = True"
      ],
      "metadata": {
        "id": "BiQDZ-fH10Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(X_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        zca_epsilon=1e-06,\n",
        "        rotation_range=0,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,\n",
        "        zoom_range=0.,\n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        steps_per_epoch=steps_per_epoch, \n",
        "                        callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IYU9MWff1wDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZz3hCl-NNLE"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=3)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ResNet for Face data",
      "provenance": [],
      "authorship_tag": "ABX9TyO/iw7arK+lKcA7IMlaf0kj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}